{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Onzt0rmh03f"
      },
      "source": [
        "Workshop 2\n",
        "Shrawan Gautam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpi5f-NuuRbg"
      },
      "source": [
        "##  **Some Helper Function:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDqrxMpLuhLO"
      },
      "source": [
        "### Softmax Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI9Ay7GRh03h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5K6BKs2h03i",
        "outputId": "d43c48de-d5c3-46d9-e6a1-23c40248448d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "   7  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.658  0.659  0.660  \\\n",
            "0  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "1  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "2  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "3  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "4  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "\n",
            "   0.661  0.662  0.663  0.664  0.665  0.666  0.667  \n",
            "0      0      0      0      0      0      0      0  \n",
            "1      0      0      0      0      0      0      0  \n",
            "2      0      0      0      0      0      0      0  \n",
            "3      0      0      0      0      0      0      0  \n",
            "4      0      0      0      0      0      0      0  \n",
            "\n",
            "[5 rows x 785 columns]\n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9999 entries, 0 to 9998\n",
            "Columns: 785 entries, 7 to 0.667\n",
            "dtypes: int64(785)\n",
            "memory usage: 59.9 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/sample_data/mnist_test.csv\") # changed to read_csv and the correct file name\n",
        "# Step 2: Dataset Information\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())  # Show first 5 rows\n",
        "print(\"\\nDataset Information:\")\n",
        "print(df.info())  # Summary of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoOjTJJpt6Nv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(z):\n",
        "    \"\"\"\n",
        "    Compute the softmax probabilities for a given input matrix.\n",
        "\n",
        "    Parameters:\n",
        "    z (numpy.ndarray): Logits (raw scores) of shape (m, n), where\n",
        "                       - m is the number of samples.\n",
        "                       - n is the number of classes.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Softmax probability matrix of shape (m, n), where\n",
        "                   each row sums to 1 and represents the probability\n",
        "                   distribution over classes.\n",
        "\n",
        "    Notes:\n",
        "    - The input to softmax is typically computed as: z = XW + b.\n",
        "    - Uses numerical stabilization by subtracting the max value per row.\n",
        "    \"\"\"\n",
        "\n",
        "    # Your Code Here.\n",
        "    z_shifted = z - np.max(z, axis=1, keepdims=True)\n",
        "    exp_z = np.exp(z_shifted)\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFnMdHJzrUJV"
      },
      "source": [
        "### Softmax Test Case:\n",
        "\n",
        "This test case checks that each row in the resulting softmax probabilities sums to 1, which is the fundamental property of softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL5ToHmkrTr-",
        "outputId": "33212172-d3b8-4a0b-96e9-780f3a55489d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax function passed the test case!\n"
          ]
        }
      ],
      "source": [
        "# Example test case\n",
        "z_test = np.array([[2.0, 1.0, 0.1], [1.0, 1.0, 1.0]])\n",
        "softmax_output = softmax(z_test)\n",
        "\n",
        "# Verify if the sum of probabilities for each row is 1 using assert\n",
        "row_sums = np.sum(softmax_output, axis=1)\n",
        "\n",
        "# Assert that the sum of each row is 1\n",
        "assert np.allclose(row_sums, 1), f\"Test failed: Row sums are {row_sums}\"\n",
        "\n",
        "print(\"Softmax function passed the test case!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1uPYyhotoAf"
      },
      "source": [
        "### Prediction Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qwCbgC1vyHn"
      },
      "outputs": [],
      "source": [
        "def predict_softmax(X, W, b):\n",
        "    \"\"\"\n",
        "    Predict the class labels for a set of samples using the trained softmax model.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d), where n is the number of samples and d is the number of features.\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c), where c is the number of classes.\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Predicted class labels of shape (n,), where each value is the index of the predicted class.\n",
        "    \"\"\"\n",
        "    z = np.dot(X, W) + b  # Compute the scores (logits)\n",
        "    y_pred = softmax(z)  # Get the probabilities using the softmax function\n",
        "\n",
        "    # Assign the class with the highest probability\n",
        "    predicted_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    return predicted_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCGDTavVuXZu"
      },
      "source": [
        "### Test Function for Prediction Function:\n",
        "The test function ensures that the predicted class labels have the same number of elements as the input samples, verifying that the model produces a valid output shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "musr99YhucQX",
        "outputId": "80281d35-e8dc-4d48-94ea-f91c9bf1a815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class labels: [1 1 0]\n"
          ]
        }
      ],
      "source": [
        "# Define test case\n",
        "X_test = np.array([[0.2, 0.8], [0.5, 0.5], [0.9, 0.1]])  # Feature matrix (3 samples, 2 features)\n",
        "W_test = np.array([[0.4, 0.2, 0.1], [0.3, 0.7, 0.5]])  # Weights (2 features, 3 classes)\n",
        "b_test = np.array([0.1, 0.2, 0.3])  # Bias (3 classes)\n",
        "\n",
        "# Expected Output:\n",
        "# The function should return an array with class labels (0, 1, or 2)\n",
        "\n",
        "y_pred_test = predict_softmax(X_test, W_test, b_test)\n",
        "\n",
        "# Validate output shape\n",
        "assert y_pred_test.shape == (3,), f\"Test failed: Expected shape (3,), got {y_pred_test.shape}\"\n",
        "\n",
        "# Print the predicted labels\n",
        "print(\"Predicted class labels:\", y_pred_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwejxbajvEle"
      },
      "source": [
        "### Loss Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjqnULCtun_Z"
      },
      "outputs": [],
      "source": [
        "def loss_softmax(y_pred, y):\n",
        "    \"\"\"\n",
        "    Compute the cross-entropy loss for a single sample.\n",
        "\n",
        "    Parameters:\n",
        "    y_pred (numpy.ndarray): Predicted probabilities of shape (c,) for a single sample,\n",
        "                             where c is the number of classes.\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (c,), where c is the number of classes.\n",
        "\n",
        "    Returns:\n",
        "    float: Cross-entropy loss for the given sample.\n",
        "    \"\"\"\n",
        "\n",
        "    epsilon = 1e-12  # To avoid log(0)\n",
        "    y_pred = np.clip(y_pred, epsilon, 1.0 - epsilon)  # Prevent log(0) by clipping values\n",
        "    n = y.shape[0]  # Number of samples\n",
        "    loss = -np.sum(y * np.log(y_pred)) / n\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXdMIV_cz5Fn"
      },
      "source": [
        "## Test case for Loss Function:\n",
        "This test case Compares loss for correct vs. incorrect predictions.\n",
        "*   Expects low loss for correct predictions.\n",
        "*   Expects high loss for incorrect predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IhRGquu0N9P",
        "outputId": "30dcbf08-ea42-4d47-814e-2c90694c4523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Entropy Loss (Correct Predictions): 0.1435\n",
            "Cross-Entropy Loss (Incorrect Predictions): 2.9957\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define correct predictions (low loss scenario)\n",
        "y_true_correct = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])  # True one-hot labels\n",
        "y_pred_correct = np.array([[0.9, 0.05, 0.05],\n",
        "                           [0.1, 0.85, 0.05],\n",
        "                           [0.05, 0.1, 0.85]])  # High confidence in the correct class\n",
        "\n",
        "# Define incorrect predictions (high loss scenario)\n",
        "y_pred_incorrect = np.array([[0.05, 0.05, 0.9],  # Highly confident in the wrong class\n",
        "                              [0.1, 0.05, 0.85],\n",
        "                              [0.85, 0.1, 0.05]])\n",
        "\n",
        "# Compute loss for both cases\n",
        "loss_correct = loss_softmax(y_pred_correct, y_true_correct)\n",
        "loss_incorrect = loss_softmax(y_pred_incorrect, y_true_correct)\n",
        "\n",
        "# Validate that incorrect predictions lead to a higher loss\n",
        "assert loss_correct < loss_incorrect, f\"Test failed: Expected loss_correct < loss_incorrect, but got {loss_correct:.4f} >= {loss_incorrect:.4f}\"\n",
        "\n",
        "# Print results\n",
        "print(f\"Cross-Entropy Loss (Correct Predictions): {loss_correct:.4f}\")\n",
        "print(f\"Cross-Entropy Loss (Incorrect Predictions): {loss_incorrect:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0d3fm1-vUlY"
      },
      "source": [
        "### Cost Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaH9_s0svIGJ"
      },
      "outputs": [],
      "source": [
        "def cost_softmax(X, y, W, b):\n",
        "    \"\"\"\n",
        "    Compute the average softmax regression cost (cross-entropy loss) over all samples.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d), where n is the number of samples and d is the number of features.\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c), where n is the number of samples and c is the number of classes.\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    float: Average softmax cost (cross-entropy loss) over all samples.\n",
        "    \"\"\"\n",
        "\n",
        "    n = X.shape[0]  # Number of samples\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "    cost = loss_softmax(y_pred, y)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eGyPFJ33tgY"
      },
      "source": [
        "### Test Case for Cost Function:\n",
        "The test case assures that the cost for the incorrect prediction should be higher than for the correct prediction, confirming that the cost function behaves as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIGAxYQt36Sr",
        "outputId": "f96cafcc-5b72-4219-d637-23b310b27d02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost for correct prediction: 0.0006234364133349324\n",
            "Cost for incorrect prediction: 0.29930861359446115\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example 1: Correct Prediction (Closer predictions)\n",
        "X_correct = np.array([[1.0, 0.0], [0.0, 1.0]])  # Feature matrix for correct predictions\n",
        "y_correct = np.array([[1, 0], [0, 1]])  # True labels (one-hot encoded, matching predictions)\n",
        "W_correct = np.array([[5.0, -2.0], [-3.0, 5.0]])  # Weights for correct prediction\n",
        "b_correct = np.array([0.1, 0.1])  # Bias for correct prediction\n",
        "\n",
        "# Example 2: Incorrect Prediction (Far off predictions)\n",
        "X_incorrect = np.array([[0.1, 0.9], [0.8, 0.2]])  # Feature matrix for incorrect predictions\n",
        "y_incorrect = np.array([[1, 0], [0, 1]])  # True labels (one-hot encoded, incorrect predictions)\n",
        "W_incorrect = np.array([[0.1, 2.0], [1.5, 0.3]])  # Weights for incorrect prediction\n",
        "b_incorrect = np.array([0.5, 0.6])  # Bias for incorrect prediction\n",
        "\n",
        "# Compute cost for correct predictions\n",
        "cost_correct = cost_softmax(X_correct, y_correct, W_correct, b_correct)\n",
        "\n",
        "# Compute cost for incorrect predictions\n",
        "cost_incorrect = cost_softmax(X_incorrect, y_incorrect, W_incorrect, b_incorrect)\n",
        "\n",
        "# Check if the cost for incorrect predictions is greater than for correct predictions\n",
        "assert cost_incorrect > cost_correct, f\"Test failed: Incorrect cost {cost_incorrect} is not greater than correct cost {cost_correct}\"\n",
        "\n",
        "# Print the costs for verification\n",
        "print(\"Cost for correct prediction:\", cost_correct)\n",
        "print(\"Cost for incorrect prediction:\", cost_incorrect)\n",
        "\n",
        "print(\"Test passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-YIb7zlveKq"
      },
      "source": [
        "### Computing Gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3Vpn5bNvW3x"
      },
      "outputs": [],
      "source": [
        "def compute_gradient_softmax(X, y, W, b):\n",
        "    \"\"\"\n",
        "    Compute the gradients of the cost function with respect to weights and biases.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d).\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    tuple: Gradients with respect to weights (d, c) and biases (c,).\n",
        "    \"\"\"\n",
        "\n",
        "    n, d = X.shape\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "\n",
        "    grad_W = np.dot(X.T, (y_pred - y)) / n  # Gradient with respect to weights\n",
        "    grad_b = np.sum(y_pred - y, axis=0) / n  # Gradient with respect to biases\n",
        "\n",
        "    return grad_W, grad_b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S84yoIUx7vY7"
      },
      "source": [
        "### Test case for compute_gradient function:\n",
        "The test checks if the gradients from the function are close enough to the manually computed gradients using np.allclose, which accounts for potential floating-point discrepancies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-YSC_Ot70bZ",
        "outputId": "63ba9d33-0f9d-4591-b352-dd7282ad743c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient w.r.t. W: [[ 0.1031051   0.01805685 -0.12116196]\n",
            " [-0.13600547  0.00679023  0.12921524]]\n",
            "Gradient w.r.t. b: [-0.03290036  0.02484708  0.00805328]\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a simple feature matrix and true labels\n",
        "X_test = np.array([[0.2, 0.8], [0.5, 0.5], [0.9, 0.1]])  # Feature matrix (3 samples, 2 features)\n",
        "y_test = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])  # True labels (one-hot encoded, 3 classes)\n",
        "\n",
        "# Define weight matrix and bias vector\n",
        "W_test = np.array([[0.4, 0.2, 0.1], [0.3, 0.7, 0.5]])  # Weights (2 features, 3 classes)\n",
        "b_test = np.array([0.1, 0.2, 0.3])  # Bias (3 classes)\n",
        "\n",
        "# Compute the gradients using the function\n",
        "grad_W, grad_b = compute_gradient_softmax(X_test, y_test, W_test, b_test)\n",
        "\n",
        "# Manually compute the predicted probabilities (using softmax function)\n",
        "z_test = np.dot(X_test, W_test) + b_test\n",
        "y_pred_test = softmax(z_test)\n",
        "\n",
        "# Compute the manually computed gradients\n",
        "grad_W_manual = np.dot(X_test.T, (y_pred_test - y_test)) / X_test.shape[0]\n",
        "grad_b_manual = np.sum(y_pred_test - y_test, axis=0) / X_test.shape[0]\n",
        "\n",
        "# Assert that the gradients computed by the function match the manually computed gradients\n",
        "assert np.allclose(grad_W, grad_W_manual), f\"Test failed: Gradients w.r.t. W are not equal.\\nExpected: {grad_W_manual}\\nGot: {grad_W}\"\n",
        "assert np.allclose(grad_b, grad_b_manual), f\"Test failed: Gradients w.r.t. b are not equal.\\nExpected: {grad_b_manual}\\nGot: {grad_b}\"\n",
        "\n",
        "# Print the gradients for verification\n",
        "print(\"Gradient w.r.t. W:\", grad_W)\n",
        "print(\"Gradient w.r.t. b:\", grad_b)\n",
        "\n",
        "print(\"Test passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W75VL71ivpjG"
      },
      "source": [
        "### Implementing Gradient Descent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbQ7SVw7vo-M"
      },
      "outputs": [],
      "source": [
        "def gradient_descent_softmax(X, y, W, b, alpha, n_iter, show_cost=False):\n",
        "    \"\"\"\n",
        "    Perform gradient descent to optimize the weights and biases.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d).\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "    alpha (float): Learning rate.\n",
        "    n_iter (int): Number of iterations.\n",
        "    show_cost (bool): Whether to display the cost at intervals.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Optimized weights, biases, and cost history.\n",
        "    \"\"\"\n",
        "\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        # Compute gradients\n",
        "        grad_W, grad_b = compute_gradient_softmax(X, y, W, b)\n",
        "\n",
        "        # Update weights and biases using the gradients\n",
        "        W -= alpha * grad_W\n",
        "        b -= alpha * grad_b\n",
        "\n",
        "        # Compute and store cost\n",
        "        cost = cost_softmax(X, y, W, b)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "        # Print cost at regular intervals\n",
        "        if show_cost and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: Cost = {cost:.6f}\")\n",
        "\n",
        "    return W, b, cost_history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBG9uSWKHDgX"
      },
      "source": [
        "## Preparing Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prZ_zAvLpodE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_prepare_mnist(csv_file, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Reads the MNIST CSV file, splits data into train/test sets, and plots one image per class.\n",
        "\n",
        "    Arguments:\n",
        "    csv_file (str)       : Path to the CSV file containing MNIST data.\n",
        "    test_size (float)    : Proportion of the data to use as the test set (default: 0.2).\n",
        "    random_state (int)   : Random seed for reproducibility (default: 42).\n",
        "\n",
        "    Returns:\n",
        "    X_train, X_test, y_train, y_test : Split dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Separate labels and features\n",
        "    y = df.iloc[:, 0].values  # First column is the label\n",
        "    X = df.iloc[:, 1:].values  # Remaining columns are pixel values\n",
        "\n",
        "    # Normalize pixel values (optional but recommended)\n",
        "    X = X / 255.0  # Scale values between 0 and 1\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Plot one sample image per class\n",
        "    plot_sample_images(X, y)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def plot_sample_images(X, y):\n",
        "    \"\"\"\n",
        "    Plots one sample image for each digit class (0-9).\n",
        "\n",
        "    Arguments:\n",
        "    X (np.ndarray): Feature matrix containing pixel values.\n",
        "    y (np.ndarray): Labels corresponding to images.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    unique_classes = np.unique(y)  # Get unique class labels\n",
        "\n",
        "    for i, digit in enumerate(unique_classes):\n",
        "        index = np.where(y == digit)[0][0]  # Find first occurrence of the class\n",
        "        image = X[index].reshape(28, 28)  # Reshape 1D array to 28x28\n",
        "\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f\"Digit: {digit}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtYR42Qas2uf",
        "outputId": "d0a196bd-c071-4589-e9a0-8cb3f29a3925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/mnist_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3c6e2b96e898>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/mnist_dataset.csv\"\u001b[0m  \u001b[0;31m# Path to saved dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_prepare_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-8e50d2cd7b7f>\u001b[0m in \u001b[0;36mload_and_prepare_mnist\u001b[0;34m(csv_file, test_size, random_state)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Separate labels and features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/mnist_dataset.csv'"
          ]
        }
      ],
      "source": [
        "csv_file_path = \"/content/mnist_dataset.csv\"  # Path to saved dataset\n",
        "X_train, X_test, y_train, y_test = load_and_prepare_mnist(csv_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyMBH4mQtzHA"
      },
      "source": [
        "### **A Quick debugging Step:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIJhtnuCs7QF"
      },
      "outputs": [],
      "source": [
        "# Assert that X and y have matching lengths\n",
        "assert len(X_train) == len(y_train), f\"Error: X and y have different lengths! X={len(X_train)}, y={len(y_train)}\"\n",
        "print(\"Move forward: Dimension of Feture Matrix X and label vector y matched.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TKIsKJcwFsv"
      },
      "source": [
        "## **Train the Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEuTbCU0xAQW"
      },
      "outputs": [],
      "source": [
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8e2mHmRv4fd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Check if y_train is one-hot encoded\n",
        "if len(y_train.shape) == 1:\n",
        "    encoder = OneHotEncoder(sparse_output=False)  # Use sparse_output=False for newer versions of sklearn\n",
        "    y_train = encoder.fit_transform(y_train.reshape(-1, 1))  # One-hot encode labels\n",
        "    y_test = encoder.transform(y_test.reshape(-1, 1))  # One-hot encode test labels\n",
        "\n",
        "# Now y_train is one-hot encoded, and we can proceed to use it\n",
        "d = X_train.shape[1]  # Number of features (columns in X_train)\n",
        "c = y_train.shape[1]  # Number of classes (columns in y_train after one-hot encoding)\n",
        "\n",
        "# Initialize weights with small random values and biases with zeros\n",
        "W = np.random.randn(d, c) * 0.01  # Small random weights initialized\n",
        "b = np.zeros(c)  # Bias initialized to 0\n",
        "\n",
        "# Set hyperparameters for gradient descent\n",
        "alpha = 0.1  # Learning rate\n",
        "n_iter = 1000  # Number of iterations to run gradient descent\n",
        "\n",
        "# Train the model using gradient descent\n",
        "W_opt, b_opt, cost_history = gradient_descent_softmax(X_train, y_train, W, b, alpha, n_iter, show_cost=True)\n",
        "\n",
        "# Plot the cost history to visualize the convergence\n",
        "plt.plot(cost_history)\n",
        "plt.title('Cost Function vs. Iterations')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH4wNbhzys4f"
      },
      "source": [
        "## **Evaluating the Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzV7BkRqOl5A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_classification(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluate classification performance using confusion matrix, precision, recall, and F1-score.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (numpy.ndarray): True labels\n",
        "    y_pred (numpy.ndarray): Predicted labels\n",
        "\n",
        "    Returns:\n",
        "    tuple: Confusion matrix, precision, recall, F1 score\n",
        "    \"\"\"\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Compute precision, recall, and F1-score\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    return cm, precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuGtvIlywK7J"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred_test = predict_softmax(X_test, W_opt, b_opt)\n",
        "\n",
        "# Evaluate accuracy\n",
        "y_test_labels = np.argmax(y_test, axis=1)  # True labels in numeric form\n",
        "\n",
        "# Evaluate the model\n",
        "cm, precision, recall, f1 = evaluate_classification(y_test_labels, y_pred_test)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "# Visualizing the Confusion Matrix\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "cax = ax.imshow(cm, cmap='Blues')  # Use a color map for better visualization\n",
        "\n",
        "# Dynamic number of classes\n",
        "num_classes = cm.shape[0]\n",
        "ax.set_xticks(range(num_classes))\n",
        "ax.set_yticks(range(num_classes))\n",
        "ax.set_xticklabels([f'Predicted {i}' for i in range(num_classes)])\n",
        "ax.set_yticklabels([f'Actual {i}' for i in range(num_classes)])\n",
        "\n",
        "# Add labels to each cell in the confusion matrix\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > np.max(cm) / 2 else 'black')\n",
        "\n",
        "# Add grid lines and axis labels\n",
        "ax.grid(False)\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('Actual Label', fontsize=12)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.colorbar(cax)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv8J5hNCPzl6"
      },
      "source": [
        "# Linear Seperability and Logistic Regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTyaPcM-P69S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification, make_circles\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "# Generate linearly separable dataset\n",
        "X_linear_separable, y_linear_separable = make_classification(n_samples=200, n_features=2,\n",
        "n_informative=2,\n",
        "\n",
        "n_redundant=0, n_clusters_per_class=1,\n",
        "random_state=42)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_linear, X_test_linear, y_train_linear, y_test_linear = train_test_split(\n",
        "X_linear_separable, y_linear_separable, test_size=0.2, random_state=42\n",
        ")\n",
        "# Train logistic regression model on linearly separable data\n",
        "logistic_model_linear_separable = LogisticRegression()\n",
        "logistic_model_linear_separable.fit(X_train_linear, y_train_linear)\n",
        "# Generate non-linearly separable dataset (circles)\n",
        "X_non_linear_separable, y_non_linear_separable = make_circles(n_samples=200, noise=0.1, factor=0.5,\n",
        "random_state=42)\n",
        "# Split the data into training and testing sets\n",
        "X_train_non_linear, X_test_non_linear, y_train_non_linear, y_test_non_linear = train_test_split(\n",
        "X_non_linear_separable, y_non_linear_separable, test_size=0.2, random_state=42\n",
        ")\n",
        "# Train logistic regression model on non-linearly separable data\n",
        "logistic_model_non_linear_separable = LogisticRegression()\n",
        "logistic_model_non_linear_separable.fit(X_train_non_linear, y_train_non_linear)\n",
        "# Plot decision boundaries for linearly and non-linearly separable data\n",
        "def plot_decision_boundary(ax, model, X, y, title):\n",
        "    h = .02 # step size in the mesh\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    ax.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Feature 1')\n",
        "    ax.set_ylabel('Feature 2')\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "# Plot decision boundary for linearly separable data (Training)\n",
        "plot_decision_boundary(axes[0, 0], logistic_model_linear_separable, X_train_linear, y_train_linear,'Linearly Separable Data (Training)')\n",
        "# Plot decision boundary for linearly separable data (Testing)\n",
        "plot_decision_boundary(axes[0, 1], logistic_model_linear_separable, X_test_linear, y_test_linear, 'Linearly Separable Data (Testing)')\n",
        "# Plot decision boundary for non-linearly separable data (Training)\n",
        "plot_decision_boundary(axes[1, 0], logistic_model_non_linear_separable, X_train_non_linear,y_train_non_linear, 'Non-Linearly Separable Data (Training)')\n",
        "# Plot decision boundary for non-linearly separable data (Testing)\n",
        "plot_decision_boundary(axes[1, 1], logistic_model_non_linear_separable, X_test_non_linear,y_test_non_linear, 'Non-Linearly Separable Data (Testing)')\n",
        "plt.tight_layout()\n",
        "# Save the plots as PNG files\n",
        "plt.savefig('decision_boundaries.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}